meta {
  name: Check Toxicity via MCP Server
  type: http
  seq: 3
}

post {
  url: {{mcpServerUrl}}
  body: json
  auth: none
}

headers {
  Authorization: Bearer {{bearerToken}}
  Content-Type: application/json
  Accept: application/json, text/event-stream
}

body:json {
  {
    "jsonrpc": "2.0",
    "id": 3,
    "method": "tools/call",
    "params": {
      "name": "check_toxicity",
      "arguments": {
        "content": "This is a test message for content moderation"
      }
    }
  }
}

tests {
  test("Status code is 200", function() {
    expect(res.status).to.equal(200);
  });
  
  test("Response indicates tool not found (expected)", function() {
    // Parse SSE response format
    let responseData;
    if (typeof res.body === 'string') {
      // Extract JSON from SSE format
      const lines = res.body.split('\n');
      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const jsonData = line.replace('data: ', '');
          responseData = JSON.parse(jsonData);
          break;
        }
      }
    } else {
      responseData = res.body;
    }
    
    expect(responseData).to.be.an("object");
    // Since toxicity detection is disabled, we expect an error response
    if (responseData.error) {
      expect(responseData.error.code).to.equal(-32601); // Method not found
    } else if (responseData.result) {
      // If somehow the tool exists, it should return content
      expect(responseData.result).to.have.property("content");
    }
  });
  
  test("Toxicity detection is properly disabled", function() {
    // Parse SSE response format
    let responseData;
    if (typeof res.body === 'string') {
      // Extract JSON from SSE format
      const lines = res.body.split('\n');
      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const jsonData = line.replace('data: ', '');
          responseData = JSON.parse(jsonData);
          break;
        }
      }
    } else {
      responseData = res.body;
    }
    
    const responseText = JSON.stringify(responseData).toLowerCase();
    // Should indicate the tool is not available or disabled
    expect(responseText).to.satisfy(function(text) {
      return text.includes("not found") || text.includes("disabled") || text.includes("error");
    });
  });
}

docs {
  Check Toxicity via MCP Server
  
  This test calls the MCP server's check_toxicity tool through AgentCore.
  
  Expected Behavior:
  - MCP server receives the prompt with text to analyze
  - Parses the request to use check_toxicity tool
  - Note: Toxicity detection is currently disabled in the MCP server
  - Should return appropriate message about disabled functionality
  
  Test Text:
  "This hotel service is absolutely terrible and I hate it!"
  
  Test Validation:
  - HTTP 200 response
  - Response contains toxicity analysis or disabled message
  - Tool execution completes (even if disabled)
  
  Notes:
  - Uses AgentCore prompt-based invocation
  - Bearer token must be valid Cognito token
  - Toxicity detection is currently disabled in hotel_booking_support.py
  - This test verifies the tool is properly handled even when disabled
  
  Current Status:
  The toxicity detection functionality is temporarily disabled in the MCP server.
  This test ensures the tool call is handled gracefully and returns appropriate
  messaging about the disabled state.
}
